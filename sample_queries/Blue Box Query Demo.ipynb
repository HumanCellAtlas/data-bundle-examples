{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploration of Queries\n",
    "\n",
    "## About\n",
    "\n",
    "This Jupyter notebook is designed to demonstrate interactions with the Blue Box query endpoint as well as the file index.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q3_DEMO-donor_MGH30\n",
      "Q3_DEMO-donor_MGH30\n",
      "Q3_DEMO-donor_MGH30\n",
      "Q3_DEMO-donor_MGH30\n",
      "Q3_DEMO-donor_MGH30\n",
      "Q3_DEMO-donor_MGH30\n",
      "Q3_DEMO-donor_MGH30\n",
      "Q3_DEMO-donor_MGH30\n",
      "Q3_DEMO-donor_MGH30\n",
      "Q3_DEMO_donor1\n",
      "Q3_DEMO-donor_MGH30\n",
      "Q3_DEMO_donor1\n",
      "Q3_DEMO-donor_MGH30\n",
      "Q3_DEMO-donor_MGH30\n",
      "Q3_DEMO-donor_MGH30\n",
      "Q3_DEMO-donor_MGH30\n",
      "Q3_DEMO-donor_MGH30\n",
      "Q3_DEMO-donor_MGH30\n",
      "Q3_DEMO_donor1\n",
      "Q3_DEMO-donor_MGH30\n",
      "Q3_DEMO_donor1\n",
      "Q3_DEMO-donor_MGH30\n",
      "Q3_DEMO-donor_MGH30\n",
      "Q3_DEMO-donor_MGH30\n",
      "Q3_DEMO-donor_MGH30\n",
      "Q3_DEMO-donor_MGH30\n",
      "Q3_DEMO-donor_MGH30\n",
      "Q3_DEMO-donor_MGH30\n",
      "Q3_DEMO-donor_MGH30\n",
      "Q3_DEMO-donor_MGH30\n",
      "Q3_DEMO-donor_MGH30\n",
      "Q3_DEMO_donor1\n",
      "Q3_DEMO-donor_MGH30\n",
      "Q3_DEMO-donor_MGH30\n",
      "Q3_DEMO-donor_MGH30\n",
      "Q3_DEMO_donor1\n",
      "Q3_DEMO-donor_MGH30\n",
      "Q3_DEMO-donor_MGH30\n",
      "Q3_DEMO_donor1\n",
      "Q3_DEMO_donor1\n",
      "Q3_DEMO-donor_MGH30\n",
      "Q3_DEMO-donor_MGH30\n",
      "Q3_DEMO_donor1\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'dict_keys' object does not support indexing",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-f47886295cc6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m \u001b[0;31m# go ahead and print summary for donors that don't have analysis\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m \u001b[0mprint_analysis_candidates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdonors_all\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdonors_with_analysis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-22-f47886295cc6>\u001b[0m in \u001b[0;36mprint_analysis_candidates\u001b[0;34m(donors, donors_to_subtract)\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mdonor\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdonors\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m         \u001b[0mdonor_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdonor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m         \u001b[0mdonor_match\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mdonor_to_subtract\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdonors_to_subtract\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'dict_keys' object does not support indexing"
     ]
    }
   ],
   "source": [
    "# imports\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import urllib.parse\n",
    "import urllib.request\n",
    "import json\n",
    "\n",
    "\n",
    "# this allows plots to appear directly in the notebook\n",
    "%matplotlib inline\n",
    "\n",
    "# read URL\n",
    "def read_url(url):\n",
    "    req = urllib.request.Request(url)\n",
    "    with urllib.request.urlopen(req) as response:\n",
    "        return(response.read())\n",
    "\n",
    "# remove donors from one array based on content of another\n",
    "def print_analysis_candidates(donors, donors_to_subtract):\n",
    "    result = {}\n",
    "    for donor in donors:\n",
    "        donor_id = list(donor.keys())[0]\n",
    "        donor_match = False\n",
    "        for donor_to_subtract in donors_to_subtract:\n",
    "            donor_id_to_subtract = list(donor_to_subtract.keys())[0]\n",
    "            if (donor_id == donor_id_to_subtract):\n",
    "                donor_match = True\n",
    "                print (\"MATCHES - Donor \"+donor_id+\" matches \"+donor_id_to_subtract+\" and will be excluded\")\n",
    "        if(not donor_match):\n",
    "            result[donor_id] = donor\n",
    "    for donor_id in result.keys():\n",
    "        print (\"ANALYSIS - this done has no analysis and should be analyzed: \"+donor_id)\n",
    "    \n",
    "    \n",
    "# parse sample info\n",
    "def download_sample_info(uuid, version):\n",
    "    sample_info = read_url('https://dss.staging.data.humancellatlas.org/v1/files/'+uuid+'?replica=aws&version='+version)\n",
    "    sample_data = json.loads(sample_info)\n",
    "    print (sample_data['donor_id'])\n",
    "    return(sample_data['donor_id'])\n",
    "    \n",
    "# parse bundle info to find donor ID\n",
    "def parse_bundle_info(bundle_url):\n",
    "    result_dict = {}\n",
    "    bundle_info = read_url(bundle_url)\n",
    "    bundle_data = json.loads(bundle_info)\n",
    "    for file in bundle_data['bundle']['files']:\n",
    "        if (file['name'] == 'sample.json'):\n",
    "            donor_id = download_sample_info(file['uuid'], file['version'])\n",
    "            result_dict[donor_id] = bundle_data\n",
    "    return(result_dict)\n",
    "\n",
    "# parse the query output and find bundle GUIDs\n",
    "def parse_query_result(query_result):\n",
    "    bundles = []\n",
    "    q_results = json.loads(query_result)\n",
    "    for bundle in q_results['results']:\n",
    "        donor_info = parse_bundle_info(bundle['bundle_url'])\n",
    "        bundles.append(donor_info)\n",
    "    return(bundles)\n",
    "\n",
    "# queries the search endpoint, returns the bundle GUIDs that match\n",
    "def query_for_bundles(query, url):\n",
    "    bundles = []\n",
    "    headers = {\"User-Agent\": \"Mozilla\", 'accept': 'application/json', 'content-type': 'application/json'}\n",
    "    data = json.dumps(query)\n",
    "    data = data.encode('ascii') # data should be bytes\n",
    "    req = urllib.request.Request(url, data, headers)\n",
    "    with urllib.request.urlopen(req) as response:\n",
    "        the_page = response.read()\n",
    "        bundles = parse_query_result(the_page)\n",
    "        return (bundles)\n",
    "        \n",
    "        \n",
    "# queries\n",
    "url = 'https://dss.staging.data.humancellatlas.org/v1/search?replica=aws'\n",
    "query_analysis = {\n",
    " \"es_query\": {\n",
    "   \"query\": {\n",
    "     \"bool\": {\n",
    "       \"must\": [\n",
    "         {\n",
    "           \"match\": {\n",
    "             \"manifest.files.name\": \"analysis.json\"\n",
    "           }\n",
    "         },\n",
    "         {\n",
    "           \"match\": {\n",
    "             \"files.sample_json.donor.species.ontology\": \"9606\"\n",
    "           }\n",
    "         },\n",
    "         {\n",
    "           \"wildcard\": {\n",
    "             \"manifest.files.name\": \"*fastq.gz\"\n",
    "           }\n",
    "         }\n",
    "       ]\n",
    "     }\n",
    "   }\n",
    " }\n",
    "}\n",
    "query_all = {\n",
    " \"es_query\": {\n",
    "   \"query\": {\n",
    "     \"bool\": {\n",
    "       \"must\": [\n",
    "         {\n",
    "           \"match\": {\n",
    "             \"files.sample_json.donor.species.ontology\": \"9606\"\n",
    "           }\n",
    "         },\n",
    "         {\n",
    "           \"wildcard\": {\n",
    "             \"manifest.files.name\": \"*fastq.gz\"\n",
    "           }\n",
    "         }\n",
    "       ]\n",
    "     }\n",
    "   }\n",
    " }\n",
    "}\n",
    "\n",
    "# now do the queries\n",
    "donors_with_analysis = query_for_bundles(query_analysis, url)\n",
    "donors_all = query_for_bundles(query_all, url)\n",
    "\n",
    "# go ahead and print summary for donors that don't have analysis\n",
    "print_analysis_candidates(donors_all, donors_with_analysis)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
